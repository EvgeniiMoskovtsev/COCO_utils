{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Notebook1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPMUskULpVlC",
        "colab_type": "code",
        "outputId": "f3f5674e-30d1-4aa3-a240-9f979944f958",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        }
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import json\n",
        "import cv2\n",
        "import random\n",
        "from math import ceil\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import models, layers, optimizers, Input, Model\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "#PATHS\n",
        "path_train_images = '/content/drive/My Drive/images/'\n",
        "path_train_jsons = '/content/drive/My Drive/jsons/'\n",
        "path_predict_images = '/content/drive/My Drive/predict_images/'\n",
        "\n",
        "#READ FILES\n",
        "image_files = glob.glob(os.path.join(path_train_images, \"*.jpg\"))\n",
        "json_files = glob.glob(os.path.join(path_train_jsons, \"*.json\"))\n",
        "predict_images = glob.glob(os.path.join(path_predict_images, \"*.JPG\"))\n",
        "\n",
        "assert len(image_files)==len(json_files), \"Number of files is not equal to masks\"\n",
        "\n",
        "#PREPARE TRAIN, TEST, VALIDATION SETS\n",
        "#set size\n",
        "train = 0.7\n",
        "test = round((1-train)/2, 2)\n",
        "validation = round(1-train-test, 2)\n",
        "\n",
        "#divide images on sets\n",
        "random.shuffle(image_files)\n",
        "train_image_files = image_files[:round(len(image_files)*train)]\n",
        "diff = np.setdiff1d(image_files, train_image_files)\n",
        "test_image_files = diff[:round(len(diff)/2)]\n",
        "val_image_files = diff[round(len(diff)/2):]\n",
        "print(len(train_image_files), len(test_image_files), len(val_image_files))\n",
        "\n",
        "#prepare json files for train set\n",
        "def filename_detection(path):\n",
        "    filename_with_ext = os.path.basename(path)\n",
        "    filename, file_extension = os.path.splitext(filename_with_ext)\n",
        "    return filename\n",
        "\n",
        "def pick_json_files(files):\n",
        "    set_json_files = []\n",
        "    for i in range(0, len(files)):\n",
        "        filename = filename_detection(files[i])\n",
        "        set_json_files.append(path_train_jsons + filename +'.json')\n",
        "    return set_json_files\n",
        "\n",
        "train_json_files = pick_json_files(train_image_files)\n",
        "test_json_files = pick_json_files(test_image_files)\n",
        "val_json_files = pick_json_files(val_image_files)\n",
        "print(len(train_json_files), len(test_json_files), len(val_json_files))\n",
        "\n",
        "#PREPARE IMAGE AND MASK TRAIN SETS AS ARRAYS\n",
        "def create_img_mask_arrays(json_files, image_files):\n",
        "    img = None\n",
        "    mask = None\n",
        "    for i in range(0, len(json_files)):\n",
        "        json_file = json_files[i]\n",
        "        img_file = image_files[i]\n",
        "        img_temp = cv2.imread(img_file)\n",
        "        img_temp = cv2.resize(img_temp, dsize=(256, 256), interpolation=cv2.INTER_CUBIC)\n",
        "        img_temp = np.array([img_temp])\n",
        "        #print(img_temp.shape)\n",
        "        if img is None:\n",
        "            img = img_temp\n",
        "        else:\n",
        "            img = np.concatenate((img, img_temp), axis=0)\n",
        "        with open(json_file, \"r\") as read_file:\n",
        "            f = read_file.read()\n",
        "            obj = json.loads(f)\n",
        "        h = obj['imageHeight']\n",
        "        w = obj['imageWidth']\n",
        "        download_img = Image.new(size = (w, h), mode = 'RGB')\n",
        "        for j in range(0, len(obj['shapes'])):\n",
        "            poly = obj['shapes'][j]['points']\n",
        "            a = []\n",
        "            for m in range(0, len(poly)):\n",
        "                poly_temp = tuple(poly[m])\n",
        "                a.append(poly_temp)\n",
        "            ImageDraw.Draw(download_img).polygon(a, outline=(255, 255, 255), fill=(255, 255, 255))\n",
        "            download_img.show()\n",
        "        mask_temp = np.array(download_img)\n",
        "        mask_temp = cv2.resize(mask_temp, dsize=(256, 256), interpolation=cv2.INTER_CUBIC)\n",
        "        mask_temp = cv2.cvtColor(mask_temp, cv2.COLOR_BGR2GRAY)\n",
        "        (threshi, mask_temp) = cv2.threshold(mask_temp, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
        "        mask_temp = np.array([mask_temp])\n",
        "        mask_temp = np.moveaxis(mask_temp, 0, -1)\n",
        "        mask_temp = mask_temp[np.newaxis, :]\n",
        "        #print(mask_temp.shape)\n",
        "        if mask is None:\n",
        "            mask = mask_temp\n",
        "        else:\n",
        "            mask = np.concatenate((mask, mask_temp), axis=0)\n",
        "    return img, mask\n",
        "\n",
        "train_img_array, train_mask_array = create_img_mask_arrays(train_json_files, train_image_files)\n",
        "val_img_array, val_mask_array = create_img_mask_arrays(val_json_files, val_image_files)\n",
        "test_img_array, test_mask_array = create_img_mask_arrays(test_json_files, test_image_files)\n",
        "print(train_mask_array.shape)\n",
        "print(train_img_array.shape)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "47 10 10\n",
            "47 10 10\n",
            "(47, 256, 256, 1)\n",
            "(47, 256, 256, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnywJIZrpK7m",
        "colab_type": "code",
        "outputId": "e583838e-ee32-40f8-edaa-05e7ab97762d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#AUGMENTATION\n",
        "bs = 4 #batch size\n",
        "'''\n",
        "batch mode: batch size = dataset size\n",
        "mini-batch mode: 1 < batch size < dataset size - better to use this\n",
        "stochastic mode: batch size = 1\n",
        "'''\n",
        "#for future: try to add deformations \n",
        "train_datagen = dict(rescale=1./255,\n",
        "                      rotation_range=40,\n",
        "                      width_shift_range=0.2,\n",
        "                      height_shift_range=0.2,\n",
        "                      shear_range=0.2,\n",
        "                      zoom_range=0.2,\n",
        "                      horizontal_flip=True,\n",
        "                      fill_mode='nearest')\n",
        "test_datagen = dict(rescale=1./255)\n",
        "\n",
        "train_image_datagen = ImageDataGenerator(**train_datagen)\n",
        "train_mask_datagen = ImageDataGenerator(**train_datagen)\n",
        "val_image_datagen = ImageDataGenerator(**train_datagen)\n",
        "val_mask_datagen = ImageDataGenerator(**train_datagen)\n",
        "test_image_datagen = ImageDataGenerator(**test_datagen)\n",
        "test_mask_datagen = ImageDataGenerator(**test_datagen)\n",
        "\n",
        "seed = 1 #to apply equal augmentations to image and mask\n",
        "train_image_datagen.fit(train_img_array, augment=True, seed=seed) #augment=True allows to augment data randomly; rounds - number of augmented images derived from original image\n",
        "train_mask_datagen.fit(train_mask_array, augment=True, seed=seed)\n",
        "train_image_generator = train_image_datagen.flow(train_img_array, seed=seed, batch_size=bs)\n",
        "train_mask_generator = train_mask_datagen.flow(train_mask_array, seed=seed, batch_size=bs)\n",
        "train_generator = (pair for pair in zip(train_image_generator, train_mask_generator))\n",
        "\n",
        "val_image_datagen.fit(val_img_array, augment=True, seed=seed)\n",
        "val_mask_datagen.fit(val_mask_array, augment=True, seed=seed)\n",
        "val_image_generator = val_image_datagen.flow(val_img_array, seed=seed, batch_size=bs)\n",
        "val_mask_generator =val_mask_datagen.flow(val_mask_array, seed=seed, batch_size=bs)\n",
        "val_generator = (pair for pair in zip(val_image_generator, val_mask_generator))\n",
        "\n",
        "test_image_datagen.fit(test_img_array, augment=True, seed=seed)\n",
        "test_mask_datagen.fit(test_mask_array, augment=True, seed=seed)\n",
        "test_image_generator = test_image_datagen.flow(test_img_array, seed=seed, batch_size=bs)\n",
        "test_mask_generator = test_mask_datagen.flow(test_mask_array, seed=seed, batch_size=bs)\n",
        "test_generator = (pair for pair in zip(test_image_generator, test_mask_generator))\n",
        "\n",
        "#if we run the code below we can see the shape of generated batches\n",
        "'''for x, y in train_generator:\n",
        "  print(x.shape)\n",
        "  print(y.shape)'''"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'for x, y in train_generator:\\n  print(x.shape)\\n  print(y.shape)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68R2N-TPfvdW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#MODEL PARAMETERS\n",
        "train_samples = len(train_img_array)\n",
        "val_samples = len(val_img_array)\n",
        "neuron_number = [16, 32, 64, 128, 256, 512, 1024]\n",
        "dropout = [0.1, 0.1, 0.2, 0.2, 0.3, 0.3, 0.3] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LV6M9Osgok51",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "15636e59-ccac-4127-9e95-28894a5e89b0"
      },
      "source": [
        "#MODEL DEFINITION\n",
        "import tensorflow as tf\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, BatchNormalization\n",
        "from keras.layers.core import Dropout, Lambda\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras import backend as K\n",
        "\n",
        "'''\n",
        "- padding = 'same' to make output size of conv2D equal to input size\n",
        "- Initializations define the way to set the initial random weights of layers\n",
        "- DROPOUT: More recent research has shown some value in applying dropout also to convolutional layers, although at much lower levels: \n",
        "  p=0.1 or 0.2. Dropout was used after the activation function of each convolutional layer: CONV->RELU->DROP.\n",
        "- BatchNormalization is used after ReLu, but before Dropout\n",
        "'''\n",
        "#c_storage = [] - do not forged to empty this variable in cycle while looking for the best combination of model parameters (if not using \"find best combination\" block, un-# this line)\n",
        "def conv_down(inputs, activation, kernel, depth):\n",
        "  for i in range(0, depth-1):\n",
        "    c = Conv2D(neuron_number[i], (3, 3), activation=activation, kernel_initializer=kernel, padding='same')(inputs)\n",
        "    c = BatchNormalization()(c)\n",
        "    c = Dropout(dropout[i])(c)\n",
        "    c = Conv2D(neuron_number[i], (3, 3), activation=activation, kernel_initializer=kernel, padding='same')(c)\n",
        "    c = BatchNormalization()(c)\n",
        "    c = Dropout(dropout[i])(c)\n",
        "    c_storage.append(c)\n",
        "    p = MaxPooling2D((2, 2))(c)\n",
        "  return p\n",
        "\n",
        "def bottom (input, activation, kernel, depth):\n",
        "  use_neuron_number = neuron_number[depth]\n",
        "  c = Conv2D(use_neuron_number, (3, 3), activation=activation, kernel_initializer=kernel, padding='same')(input)\n",
        "  c = BatchNormalization()(c)\n",
        "  c = Dropout(dropout[depth])(c)\n",
        "  c = Conv2D(use_neuron_number, (3, 3), activation=activation, kernel_initializer=kernel, padding='same')(c)\n",
        "  c = BatchNormalization()(c)\n",
        "  c = Dropout(dropout[depth])(c)\n",
        "  return c\n",
        "\n",
        "def conv_up (input, activation, activation_last_layer, kernel, depth):\n",
        "  for i in reversed(range(0, depth-1)):\n",
        "    u = Conv2DTranspose(neuron_number[i], (2, 2), strides=(2, 2), padding='same')(input)\n",
        "    u = concatenate([u, c_storage[i]])\n",
        "    c = Conv2D(neuron_number[i], (3, 3), activation=activation, kernel_initializer=kernel, padding='same')(u)\n",
        "    c = BatchNormalization()(c)\n",
        "    c = Dropout(dropout[i])(c)\n",
        "    c = Conv2D(neuron_number[i], (3, 3), activation=activation, kernel_initializer=kernel, padding='same')(c)\n",
        "    c = BatchNormalization()(c)\n",
        "    c = Dropout(dropout[i])(c)\n",
        "  output = Conv2D(1, (1, 1), activation=activation_last_layer)(c)\n",
        "  return output\n",
        "\n",
        "def unet_model(depth, activation, activation_last_layer, kernel, optimizer, loss, metric):\n",
        "  inputs = Input(shape=(256, 256, 3))\n",
        "  p_down = conv_down(inputs, activation, kernel, depth)\n",
        "  c_bottom = bottom(p_down, activation, kernel, depth)\n",
        "  outputs = conv_up(c_bottom, activation, activation_last_layer, kernel, depth)\n",
        "  model = Model(inputs=[inputs], outputs=[outputs])\n",
        "  model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
        "  model.summary()\n",
        "  results = model.fit_generator(train_generator, validation_data=val_generator, validation_steps=ceil(val_samples/bs), \n",
        "                              steps_per_epoch = ceil(train_samples/bs), epochs=75)\n",
        "  return model, results\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfHJtWLqiTjn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SINGLE MODEL RUN\n",
        "c_storage = []\n",
        "depth = 5\n",
        "activation = 'relu'\n",
        "activation_last_layer = 'tanh'\n",
        "kernel = 'he_normal'\n",
        "optimizer = 'adam'\n",
        "loss = 'binary_crossentropy'\n",
        "metric = 'binary_accuracy'\n",
        "model, result = unet_model(depth, activation, activation_last_layer, kernel, optimizer, loss, metric)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWSQRwWNfDJQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#MULTIPLE MODEL RUN - FIND BEST COMBINATION\n",
        "metr_result = {}\n",
        "loss_result = {}\n",
        "metr_val_result = {}\n",
        "loss_val_result = {}\n",
        "kernels = ['Zeros', 'Ones', 'RandomNormal', 'RandomUniform', 'TruncatedNormal', 'VarianceScaling', 'he_uniform', 'Orthogonal', \n",
        "           'Identity', 'lecun_uniform', 'glorot_normal', 'glorot_uniform', 'he_normal', 'lecun_normal']\n",
        "activations = ['selu', 'elu', 'relu', 'linear', 'exponential', 'hard_sigmoid', 'sigmoid', 'tanh', 'softsign', 'softplus', 'softmax']\n",
        "optimizers = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
        "losses = ['mean_squared_error', 'mean_absolute_error', 'mean_absolute_percentage_error', 'mean_squared_logarithmic_error', 'squared_hinge',\n",
        "          'hinge', 'logcosh', 'huber_loss', 'binary_crossentropy', 'kullback_leibler_divergence', 'poisson', 'cosine_proximity']\n",
        "activations_last_layer = ['tanh', 'sigmoid']\n",
        "metrics = ['accuracy', 'binary_accuracy', 'cosine_proximity']\n",
        "depths = [2, 3, 4, 5, 6]\n",
        "'''\n",
        "depths = [4, 5]\n",
        "kernels = kernels[0:1]\n",
        "activations = activations[0:1]\n",
        "optimizers = optimizers[0:1]\n",
        "losses = losses[0:1]\n",
        "activations_last_layer = activations_last_layer[0:1]\n",
        "metrics = metrics[0:2]\n",
        "'''\n",
        "for depth in depths:\n",
        "  for activation_last_layer in activations_last_layer:\n",
        "    for kernel in kernels:\n",
        "      for activation in activations:\n",
        "        for optimizer in optimizers:\n",
        "          for loss in losses:\n",
        "            for metric in metrics:\n",
        "              c_storage = []\n",
        "              model, result = unet_model(depth, activation, activation_last_layer, kernel, optimizer, loss, metric)\n",
        "              loss_result.update({str(depth)+' '+str(activation)+' '+str(activation_last_layer)+' '+str(kernel)+' '+str(optimizer)+' '+str(loss)+' '+str(metric):result.history['loss']})\n",
        "              loss_val_result.update({str(depth)+' '+str(activation)+' '+str(activation_last_layer)+' '+str(kernel)+' '+str(optimizer)+' '+str(loss)+' '+str(metric):result.history['val_loss']})\n",
        "              metr_result.update({str(depth)+' '+str(activation)+' '+str(activation_last_layer)+' '+str(kernel)+' '+str(optimizer)+' '+str(loss)+' '+str(metric):result.history[str(metric)]})\n",
        "              metr_val_result.update({str(depth)+' '+str(activation)+' '+str(activation_last_layer)+' '+str(kernel)+' '+str(optimizer)+' '+str(loss)+' '+str(metric):result.history['val_'+str(metric)]})\n",
        "\n",
        "#Найти информацию как это оценить, чтобы найти наилучшую комбинацию"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWPPCBBhhyhq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#MULTIPLE MODEL EVELUATION - IN CASE OF LOW NUMBER OF COMBINATIONS - ЕЩЕ НЕ ДОДЕЛАЛА\n",
        "\n",
        "#print(len(list(acc_result.items())))\n",
        "#print(len(list(loss_result.items())))\n",
        "#print(len(list(acc_val_result.items())))\n",
        "#print(len(list(loss_val_result.items())))\n",
        "leng = len(list(acc_result.items()))\n",
        "length = len(list(loss_result.values())[0])\n",
        "print(length)\n",
        "\n",
        "epochs = range(1, length + 1)\n",
        "print(len(epochs))\n",
        "\n",
        "ax = plt.gca()\n",
        "#print(list(loss_result.keys())[1])\n",
        "#print(list(loss_result.values())[1])\n",
        "\n",
        "for i in range(0, leng):\n",
        "  print(i)\n",
        "  color = next(ax._get_lines.prop_cycler)['color']\n",
        "  plt.plot(epochs, list(loss_result.values())[i], color = color, label='Training loss: '+ str(list(loss_result.keys())[i])) \n",
        "plt.title('Training losses')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znuaaHSPpdIO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SINGLE MODEL EVALUATION\n",
        "\n",
        "acc =result.history['acc'] #['****'] depends on metric\n",
        "val_acc = result.history['val_acc']\n",
        "loss = result.history['loss']\n",
        "val_loss = result.history['val_loss']\n",
        "print('train acc: ', np.mean(acc))\n",
        "print('val acc: ', np.mean(val_acc))\n",
        "print('train loss: ', np.mean(loss))\n",
        "print('val loss: ', np.mean(val_loss))\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss') \n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss') \n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "test_samples = len(test_image_files)\n",
        "test_loss, test_acc = model.evaluate_generator(test_generator, steps=ceil(test_samples/bs))\n",
        "print('test acc:', np.mean(test_acc))\n",
        "print('test loss:', np.mean(test_loss))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53aNq-iKlICP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#PREDICT MASK\n",
        "#prepare image for prediction\n",
        "predict_images = glob.glob(os.path.join(path_predict_images, \"*.JPG\"))\n",
        "img_predict = cv2.imread(predict_images[0])\n",
        "img_predict = cv2.resize(img_predict, dsize=(256, 256), interpolation=cv2.INTER_CUBIC)\n",
        "img_predict = img_predict[np.newaxis, :]\n",
        "\n",
        "#predict\n",
        "result = model.predict(img_predict)\n",
        "result=np.squeeze(result)\n",
        "result[result > .5] = 255\n",
        "result[result <= .5] = 0\n",
        "\n",
        "#show image and predicted mask\n",
        "cv2_imshow(img_predict)\n",
        "cv2_imshow(result)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}